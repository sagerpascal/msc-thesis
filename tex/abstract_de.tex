Deep Learning hat sich im letzten Jahrzehnt im Bereich der automatischen Bildanalyse als Standard-Technologie etabliert.
Trotz beeindruckender Ergebnisse weist diese Technologie diverse Schwächen auf, wie begrenzte Robustheit gegenüber Störsignalen, eingeschränkte Transformationsinvarianz bei der Objekterkennung sowie den Bedarf an umfangreichen Trainingsdaten.
Im Gegensatz dazu sind diese Schwächen im menschlichen Gehirn kaum vorhanden.
Dies resultiert aus der nicht-sequenziellen Verarbeitung extrahierter Bildmerkmale und der Fähigkeit, eine visuelle Szene als mehr als die Summe ihrer Teile zu interpretieren, wie es die Gestalt-Psychologie beschreibt. Zudem bildet das Gehirn Konsistenz an jedem Punkt im Netzwerk mittels Selbst-Organisation und lokalem Lernen, d.h. jede Zelle kann die Aktivität von benachbarten Zellen vorhersagen und es wird durch gegenseitigen Zellsupport ein Konsens zwischen allen Merkmalen gebildet. Dadurch kann das ``Early Commitment''-Problem gelöst werden, welches inhärent in tiefen neuronalen Netzwerken vorhanden ist, da neuronale Netzwerke Konsistenz nur an einer Stelle zwischen einer Vorhersage und einem Lernsignal mittels globalem Fehlerkorrekturalgorithmus bilden.

Basierend auf diesen Erkenntnissen wird in dieser Thesis ein neues Bildverarbeitungs-Framework vorgeschlagen, das sich stark an der Funktionsweise des menschlichen Gehirns orientiert.
Entsprechend widmet sich ein bedeutender Teil dieser Thesis der Identifizierung und Interpretation von neurowissenschaftlichen Erkenntnissen.
Diese Erkenntnisse werden analysiert und in ein Computerframework übertragen, wobei den einzelnen Komponenten des Frameworks eindeutige Rolle zugewiesen und jeweils ihre Relation zum biologischen Lernen verdeutlicht wird.

Das Framework besteht aus drei Komponenten: Dem Sensorsystem \emph{S0}, welches Low-Level Merkmale aus den Bildern extrahiert; der Feature-Building Stage \emph{S1}, welche mithilfe lateralen (intra-layer) Verbindungen Neuronengruppen, sogenannte Netzfragmente, bildet, die sich gegenseitig stützen und dadurch bekannte Muster stabilisieren; der Prototyp Stage \emph{S2}, welche die gebildeten Netzfragmente  mittels Projektionsphasern zu Objekt-Prototypen mappt sowie Feedback an \emph{S1} gibt.
Dieser Projektionsprozess ist iterativ und dauert bis eine Konsistenz an jedem Punkt im Netzwerk erreicht wird, d.h. bis Zellen und Synapsen einen stabilen Zustand erreicht haben.

Während frühere Forschung bereits die Effizienz von Projektionsphasen gezeigt hat, ist die Implementierung von Netzfragmenten in \emph{S1} mehrheitlich unerforscht.
Folglich wird in dieser Arbeit die Implementierung dieser Komponente im Detail untersucht und anhand von Experimenten auf einem einfachen Datensatz mit geraden Linien diskutiert. Die Ergebnisse der Experimente zeigen, dass laterale Verbindungen, trainiert mit Hebbian Learning, tatsächlich zum Zellsupport genutzt werden kann.
Mithilfe des Zellsupports weist das Netzwerk eine deutlich höhere Robustheit gegenüber Rauschsignalen auf und kann bis zu $91.7\%$ der unerwünscht durch Störsignale aktivierten Zellen deaktivieren. Zudem können unterbrochene Linien aufgrund der lateralen Unterstützung wiederhergestellt werden. Mit einer Reichweite der lateralen Verbindungen von $11$ Pixeln können Unterbrechungen von bis zu $8$ Pixeln rekonstruiert werden, mit zusätzlichem Feedback von \emph{S2} sogar Unterbrüche bis zu $20$ Pixel. Eine Ausarbeitung des vorgeschlagenen Frameworks könnte Schwächen von neuronalen Netzwerken reduzieren und wird als vielversprechende alternative Forschungsrichtung angesehen.
