Deep Learning Systeme haben in den letzten Jahren beeindruckene Resultate erzielt und können unter anderem mit hoher Qualität Texte übersetzen, Unterhaltungen führen oder Bilder generieren. Diese Systeme werden typischerweise mit Backpropagation of Error über sämtliche Netzwerklayer hinweg als ein grosses System trainiert. Dieser Prozess ist zwar für spezifische Task der Bildanalyse wie Klassifizierung sehr effizient, ist aber neurowissenschaftlich nicht plausibel und hat verschiedenste Schwächen wie fehlende Robustheit und Interpretierbarkeit sowie (noch) nicht die Fähigkeit kausale Schlussfolgerungen zu ziehen.

In dieser Thesis werden neurowissenschaftliche Erkenntnisse identifiziert, die für die Intelligenz von Lebewesen wie dem Menschen elementar sind und auf Deep Learning Systeme adaptiert. Der Fokus liegt dabei auf dem visuellen Cortex als biologische Inspirationsquelle und Deep Learning Architekturen zur Bildanalyse als Zielsystem. Neurowissenschaftliche Erkenntnisse beziehen sich auf biologische Neuronen, welche sich gegenseitig durch zeitabhängige Spannungsspitzen anregen oder hemmen. Deep Learning Systeme hingegen haben keine Zeitdynamik und haben Aktivierungen basierend auf mathematischen Funktionen anstelle von Stromimpulsen. Folglich können Erkenntnisse nicht direkt übernommen werden und ein grosser Beitrag dieser Arbeit besteht darin die neurowissenschaftlichen Erkenntnisse in den Kontext von Deep Learning zu überführen. Spezifisch werden Vorschläge gemacht wie Selbst-Organisation, Netzfragmente und laterale Verbindungen zur Verbesserung von Deep Learning Systemen genutzt werden könnten.

Die abgeleiteten Erkenntnisse werden in Form von zwei konkreten Modellen implementiert. Dabei ist der Fokus auf der Untersuchung neuer Architekturideen und nicht auf dem Überbieten von Metriken wie Genauigkeit auf Benchmark-Datensätzen. Zudem orientieren sich die vorgeschlagenen Architekturen nahe am bewährten Deep Learning Framework und sind nicht als biologisch plausible Systeme zu verstehen. Konkret wird ein Modell mit horizontaler und ein Modell mit vertikaler Selbst-Organisation vorgeschlagen. Das Modell mit horizontaler Selbst-Organisation optimiert jedes Modell-Layer separat mit Proxy-Fehlerfunktionen. Dabei werden neue Konzepte vorgestellt, die es erlauben alle Layer gleichzeitig zu trainieren und trotzdem hierarchische Features über die Layer hinweg zu erlernen. Das zweite Modell mit vertikaler Selbst-Organisation teilt die Eingabedaten in kleinere Einheiten auf und verteilt diese auf unabhängig trainierte Variational Autoencoders. Dabei sieht jedes Modell nur ein Teil der Eingabedaten und ist auf eine lokale Interaktion mit seinen Nachbarmodellen angewiesen, um eine passende Bildrepräsentation abzuleiten.

TODO: Schlussfolgerung / Erkenntnisse sobald Experimente abgeschlossen sind.


