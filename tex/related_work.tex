%% related_work.tex

\section{Natural Intelligence}\seclbl{natural_intelligence}
This thesis is inspired by the work ''A Theory of Natural Intelligence` from von der Malsburg et al. \sidecite{von_der_Malsburg_Stadelmann_Grewe_2022}.
Therefore, we dedicate this section to summarize their work in detail.

According \cite{von_der_Malsburg_Stadelmann_Grewe_2022}, the process of learning is influenced by ``nature'', ``nurture'', and ``emergence''\sidenote{nature refers to the influence of genes and evolution, nurture to the influence of experience and education}.
They point out that human genome (as of nature) only contain 1GB of information \sidecite{hbcrd} and humans only absorb a few GB into permanent memory over a lifetime (as of nurture) but it requires about 1PB to describe the connectivity in human brain.
Therefore, it is important to distinguish the amount of information to describe a structure from the amount of information needed to generate it.
Similar, nature and nurture only require a few GB to construct, respectively instruct the entire human brain.
Therefore, they argue that the human brain must be highly structured (i.e. nature and nurture ``generate'' the human brain by selecting from a set pre-structured patterns).
The authors call the process of generating the highly structured network in the human brain the ``Kolmogorov \sidecite{Kolmogorov_1998} Algorithm of the Brain''\sidenote{as the Kolmogorov complexity describes the number of bits required by the shortest algorithm that can generate the structure}.
Network self-organization is the only mechanism that has not yet been disproved by experiments as the brains Kolmogorov algorithm \sidecite{Willshaw_VonDerMalsburg_1976, Willshaw_VonDerMalsburg_1979}.
This mechanism loops between activity and connectivity, with activity acting back on connectivity through synaptic plasticity until a steady state, called an attractor network, is reached.
The consistency property of an attractor network means that a network has many alternative signal pathways between pairs of neurons \sidecite{Malsburg_1987}.
Thus, the brain develops as an overlay of attractor networks called net-fragments \sidecite{vonderMalsburg_2018}.
Net-fragments consist of small sets of neurons, whereby each neuron can be part of several net fragments.
The network self-organization has to start from an already established coarse global structure which is improved in a coarse-to-fine manner to avoid being caught in a local optima.

Also, von der Malsburg et al. \cite{von_der_Malsburg_Stadelmann_Grewe_2022} discuss scene representation (i.e. how a scene is represented in the brain) even tough they point out that this is a contested concept \sidecite{freeman1990representations}.
Scene representation is a organization framework to put abstract interpretation of scene layouts, elements, potential actions, and emotional responses in relation.
The details are not rendered as in photographic images but the framework supports the detailed reconstructions of narrow sectors of the scene.
The basic goal if learning is to integrate a behavioral schema into the flow of scene representations.
They propose the hypothesis that the network structure resulting from self-organization together with the neural activation in the framework of scene representation are the inductive bias that tunes the brain to the natural environment.

Finally, they discuss how net fragments can be used to implement such structures and processes using vision as an example.
They point out that a neuron is grouped in one or multiple net fragments through network self-organization.
The net fragments can be considered as filters that detect previously seen patterns in the visual input signal.
An object is represented by multiple net fragments, where each fragment responds to the surface of that object and has shared neurons and connections with other net fragments representing that object.
Thus, net fragments render the topological structure of the surfaces that dominate the environment.
Von der Malsburg et al. \cite{von_der_Malsburg_Stadelmann_Grewe_2022} propose that net fragments represent shape primitives which can adapt to the shape of actual objects\sidenote{adapt in spite of metric deformations, depth rotation, and position}.
Shifter circuits are one possible implementation of networks that enable invariant responses to the position- and shape-variant representations \sidecite{Arathorn_2002, Olshausen1995}.
They are composed of net-fragments that can be formed by network self-organization \sidecite{Fernandes_vonderMalsburg_2015}.
Ref. \cite{von_der_Malsburg_Stadelmann_Grewe_2022} also argue that net fragments are the compositional data structure used by the brain.
A hierarchy of features may be represented by nested net fragments of different size.
Complex objects, such as mental constructs, can thus be seen as larger net fragments composed as mergers of pre-existing smaller net fragments.


\section{Self-Organization}}\seclbl{self_org_related}
The human brain is self-organizing \sidecite{kelso1995dynamic}.
Self-organization is the process by which systems consisting of many units spontaneously acquire their structure or function without interference from a external agent or system.
The absence of a central control unit allow self-organizing systems to quickly adjust to new environmental conditions.
Additionally, such systems have in-built redundancy with a high degree of robustness as they  are made of many simpler individual units.
These individual units can even fail without the overall system breaking down.
Dresp \sidecite{Dresp2020SevenPO} describes seven clearly identified properties of self-organization in the human brain: (i) modular connectivity, (ii) unsupervised learning, (iii) adaptive ability, (iv) functional resiliency, (v) functional plasticity, (vi) from-local-to-global functional organization, and (vii) dynamic system growth.

Before summarizing the literature specific to self-organization of neural networks, the general literature on self-organization with a focus on deep learning is described in the following.
Many of these fundamental algorithms for self-organization serve as inspiration for how ANNs can be designed to be self-organizing.

In nature, groups of millions units that solve complex tasks by using only local interactions can be observed.
For example, ants can navigate difficult terrain with a local pheromone-based communication and thus form a collective type of intelligence.
Such observations inspired researchers to build algorithms which are based on local communication and self-organization, for example ant colony optimization algorithms \sidecite{dorigo1997ant}.
DeepSwarm \sidecite{Byla_Pang_2020} is a neural architecture search method that uses this algorithm to search for the best neural architecture.
This methods achieves competitive performance on rather small datasets such as MNIST, Fashion-MNIST, and CIFAR-10.

%Robotic is another research area that uses ideas from collective intelligence such as self-assembly or self-organization.
%For example, swarm systems consist of multiple robots that work together to solve complex tasks \sidecite{Hamann_2018}.
%A famous example of self-assembling robots was presented in 2014 by Rubenstein et al. \sidecite{Rubenstein_Cornejo_Nagpal_2014}.
%They teach kilobots\sidenote{kilobots are 3.3cm tall low-cost swarm robots developed at Harvard University} to self-assemble into target shapes such as letters or stars solely based on local communication between robots.
%However, the kilobots still rely on hand-crafted algorithms to determine their position in the global coordinate system.

%TODO: Write more about swarm intelligence or delete thie paragraph above (does not really fit in here....)

Cellular Automata mimic developmental processes in multi-cell organisms.
They contain a grid of similar cells with an internal state which is updated periodically.
The transition from a given state to a subsequent state is defined by some update rules.
During an update, cells are only allowed to communicate with the neighbouring cells.
Thus, self-organization is enforced by the definition of the update rules.
Such automata can be used to study biological pattern formations \sidecite{Wolfram1984} or physical systems \sidecite{VICHNIAC198496}.
Neural Cellular Automata \sidecite{Wulff1992LearningCA} use neural networks to learn the update rule.
The input in such a neural network is the state of a given cell and its neighbours, the output the subsequent cell state.
Usually, the same network is applied to all cells.
In this case, a fully connected neural network which is applied to each cell and its local neighbours can be reformulated as a CNN\sidecite{PhysRevE}.
NCAs can be trained efficiently with gradient descent to grow given 2D patterns such as images\sidecite{48963, Mordvintsev_Randazzo_Fouts_2022}.
These images are grown through self-organisation (i.e. the pixels pick a color based on the color of neighboring pixels) and are surprisingly resistant to damage.
For example, large parts of the images can be removed and the system is able to rebuild these pixels\sidenote{a demo of this regeneration process is available at \cite{NCAs_distill}}.
However, the aforementioned approaches can only grow the pattern they were trained on.
A recent method called Variational Neural Cellular Automata \sidecite{Palm_GonDuque_Sudhakaran_Risi_2022} use an NCA as decoder of a Variational Autoencoder \sidecite{Kingma_Welling_2014}.
This probabilistic generative model can grow a large variety of images from a given input encoded in a vector format.
However, there is still a big gap in performance compared to state-of-the-art generative models.
Besides growing 2D patterns, NCAs can also create 3D patterns such as buildings in the popular video game Minecraft by utilizing 3D CNNs \sidecite{Sudhakaran_Grbic_Li_Katona_Najarro_Glanois_Risi_2021} or generate structures with specific function such as simulated robots able to locomote\sidecite{Horibe_Walker_Risi_2021}.
Moreover, self-assembling approaches based on NCAs are not restricted to grid-structures.
NCAs can be generalized to graph neural networks \sidecite{Grattarola_Livi_Alippi_2021}.
Graph cellular automata (GCA) use graph neural networks \sidecite{Zhou_Cui_Hu_Zhang_Yang_Liu_Wang_Li_Sun_2021} instead of CNNs to learn the state transition rules and can thus deal with more complex pattern structures than just 2D and 3D grids.
NCAs can even be used to control reinforcement learning (RL) agents.
Variengien et al. \sidecite{Variengien_Nichele_Glover_Pontes_Filho_2021} use the observations of the environment as state of the NCA, the subsequent state predicted by the NCA are used as Q-value estimates of a deep Q-learning algorithm \sidecite{Mnih_Kavukcuoglu_Silver_Graves_Antonoglou_Wierstra_Riedmiller_2013}.

Self-organization can not only be used to generate structures but also to optimize the weights of a neural networks over the agents lifetime.
For example, a Hebbian learning rule for meta-learning can be used to self-organize the weights of a RL agent over his lifetime\sidecite{NEURIPS2020_ee23e7ad}.
This means that across multiple episodes the weights of a Hebbian based model are learned.
The weights of the agents policy are reset in every episode and the Hebbian based model is used to update them.
This allows the agent to adapt better to the changed conditions within the environment.

Besides optimizing the weights, self-organization has also been used to change the learning rule itself.
The method ``Evolve and Merge`` \sidecite{Pedersen_Risi_2021} uses the so called ``ABCD'' Hebbian learning rule which updates the weights as follows:
\begin{equation}\eqlbl{McCulloch_Pitts_act}
	\Delta w_{ij} = \alpha (A o_i o_j + B o_i + C o_j + D)
\end{equation}%

$\alpha$ is the learning rate, $o_i$ and $o_j$ are the activity levels of connected neurons and $A$, $B$, $C$, and $D$ are learned constants.
For each connection in the network is one learning rule initialized and the constants are learned.
After a pre-defined number of epochs, the learning rules are clustered and the ones with similar constants are merged.
By repeating this process, the number of parameters can be reduced and robustness increases according to the authors.

Alternatively, it is also possible to initialize the network with shared parameters instead of starting with many rules and merging them over time.
Kirsch and Schmidhuber \sidecite{kirsch2021meta} use multiple tiny recurrent neural networks (RNNs) that have the same weight parameters but different internal states\sidenote{Intuitively, these tiny RNNs can be interpreted as more complex neurons.}.
By using self-organization and Hebbian learning, they show that it is possible to learn powerful learning algorithms such as backpropagation while running the network in forward-mode mode only.
However, it works only for small-scale problems as it can get stuck in local optima.
In general seem self-organizing systems to be hard to optimize and only to work for small datasets or simple problems so far.

Risi \sidecite{risi2021selfassemblingAI} describes why self-organizing systems are hard to train;
First, the system is hard to control because there is no central entity in charge but the system must still be nudges into the right direction.
Second, self-organizing systems are unpredictable (i.e. there exist no mathematical model that tells the outcome of the self-organizing process).


\subsection{Self-Organization in Spiking Neural Networks}\seclbl{self_org_spiking}
Spiking neural networks (SNNs) (c.f. Section \secref{spiking_networks}) communicate through binary signals known as spikes and are very efficient on special event-based hardware\sidecite{8259423}.
There exist several methods to self-organize such architectures.
For the sake of completeness, two well-known approaches are described in the following.
However, since this thesis focuses on self-organization in Deep Learning systems, these approaches are only roughly described and for detailed explanations please refer to the respective literature.

Similar to deep learning, there exists a multitude of different network architectures; Shallow \sidecite{masquelier2007unsupervised, 6469239} and deep networks \sidecite{kheradpisheh2018stdp, mozafari2019bio} structures, fully connected \sidecite{diehl2015unsupervised} and convolutional layers \sidecite{cao2015spiking, tavanaei2016bio}, as well as based on different learning rules such as supervised \sidecite{diehl2015fast, zenke2018superspike}, unsupervised \sidecite{diehl2015unsupervised, ferre2018unsupervised} and reinforcement learning based \sidecite{mozafari2018first}.

A representable method for self-organization in SNNs is proposed by Raghavan et al. \sidecite{Raghavan_Lin_Thomson_2020}.
They introduce a stackable tool-kit to assemble multi-layer neural networks.
This tool-kit is a dynamical system that encapsulates the dynamics of spiking neurons, their interactions as well as the plasticity rules that control the flow of information between layers.
Based on the input, spatio-temporal waves are generated that travel across multiple layers.
A dynamic learning rule tunes the connectivity between layers based on the properties of the waves tiling the layers\sidenote{for more information please refer to \cite{Raghavan_Lin_Thomson_2020}}.

An alternative method proposed by Raghavan and Thomson \sidecite{Raghavan2019NeuralNG} grows a neural network.
They start with a single computational ``cell'' and use a wiring algorithm to generate a pooling architecture in a self-organizing fashion.
The pooling architecture emerges through two processes; First, a layered neural network is grown. Second, self-organization of its inter-layer connections is used to form defined ``pools'' or receptive fields.
They us the Izikhevich neuron model \sidecite{Izhikevich_2003} in the first layer to generate spatio-temporal waves.
The units in the second layer learn the ``underlying'' pattern of activity generated in the first layer. 
Based on the learned patterns, the inter-layer connections are modified to generate a pooling architecture\sidenote{for more information please refer to \cite{Raghavan2019NeuralNG}}.

In general, SNNs have to ``convert'' static input data such as images to a dynamic signal.
For example, images are often converted to such signals by using Difference of Gaussian (DoG) convolution filters \sidecite{Vaila_Chiasson_Saxena_2019, KHERADPISHEH201856}.
Such filters subtract one Gaussian blurred version of an original image from another, less blurred version\sidenote{DoG filter can thus be used to reduce noise and to detect edges}.
This subtraction results in spikes for each pixel.
To encode the filter output into a temporal signal, bigger spikes are forwarded earlier in time than smaller spikes.
However, such approaches lose a lot of information about the input.
For example, in the process described above are all information about color and thin structures lost.
To the author of this thesis, this seems to be the reason why these SNNs can't match the performance of deep learning algorithms so far and often only work well for small gray-scale image-datasets such as MNIST.

\section{Correlation within CNNs}
Self-organization in neural networks can be done based on the input data.
If Hebbian learning is used\sidenote{``Cells that fire together wire together''}, cells are connected based on their correlation (i.e. cells with a high correlation are wired together).
One way to capture the correlation within CNNs are Gram matrices.
Gram matrices are essentially the dot-product between the channels of a feature map and can capture the style of given image.
They are for example used for image style transfer\sidecite{Gatys_Ecker_Bethge_2015} or related fields such as texture synthesis \sidecite{Gatys_Ecker_Bethge_20152}.
Appendix \chref{image_style_transfer} provides an intuitive explanation what image style transfer is and how it is related to Gram matrices.

A Gram matrix can be calculated based on the output of a convolutional layer.
Each filter of a convolutional layer (i.e. each channel) produces a so called convolutional map.
A convolutional map contains information about the content of the image such as object structure and positioning as well as information about the style.
Calculating a Gram matrix eliminates content-related information from the convolutional layer output but does not affect style information (c.f. Appendix \chref{image_style_transfer}).
A Gram matrix calculates the correlations between the convolutional maps (i.e. between the filter responses) of a convolutional layer output.
For a convolutional filter output $F$ of layer $l$ and two flattened convolutional maps $i$ and $j$ it is defined as \sidecite{7780634}:

\begin{equation}\eqlbl{Gram_mat}
		G_{ij}^{l} = \sum_k F^{l}_{ik} \cdot F^{l}_{jk}
\end{equation}%

Thereby, $k$ is a hyperparameter defining how many elements of the convolutional output $F$ are compared.
Gatys et al. \sidecite{7780634} applied this formula the first time to convolutional filters but did not fully explain why it works.
However, they found that the style is captured well in the correlation between convolutional maps.
Later, it was shown \sidecite{10555531720773172198} that matching the Gram matrices between two convolutional filters can be reformulated as minimizing the Maximum Mean Discrepancy (MMD) \sidecite{JMLRv13gretton12a} and thus that the style information is intrinsically represented by the distribution of activations in a CNN.

Intuitively, several filters together can describe the style of the image.
For example, if one filter reacts to vertical white and black lines and a second filter reacts to horizontal white and black lines and the input image has a checkerboard style, then these two filters have a high correlation, which is reflected in the Gram Matrix (c.f. Appendix \chref{image_style_transfer}).

Wenn Hebbian learning zur selbst-organisation verwendet wird, dann werden Neuronen von Filtern verbunden die häufig zusammen ansprechen.
Ein Datensatz beinhaltet oftmals spezifische Muster, welche in der Gram Matrix repräsentiert sind\sidenote{Nachfolgend wird der Begriff Muster statt Style verwendet, da die Gram matrix nicht nur Styles wie im Sinne von fotorealistisch, Zeichnung, o-ä. representieren kann, sondern irgendwelche nicht kontentbezogene Informationen.
Beispielsweise könnte bei einem Tierdatensatz ein Filter bei weisser Farbe, ein zweiter Filter bei schwarzen vertikalen Linien und ein dritter Filter bei schwarzen Punkten eine hohe Aktivierung haben.
Bei einem Foto eines Zebreas hätte der erste und der zweite Filter eine hohe Korrelation während bei einem Dalmatiner der erste und der dritte Filter eine hohe Korrelation aufweisen würden.}.
Somit werden also Neuronen verbunden, die alleine einen gewissen Filter repräsentieren aber zusammen für ein gewisses komplexeres Muster stehen.



When Hebbian learning is used for self-organization, neurons of filters that often trigger together are connected.
A dataset usually contains specific patterns, which are represented in the Gram Matrix\sidenote{In the following the term pattern is used instead of style, because the Gram matrix can represent not only styles like photorealistic images, drawings, etc., but any non-content related information.
For example, for an animal dataset, one filter could have high activation on white color, a second filter on black vertical lines, and a third filter on black dots.
For a photo of a zebra, the first and second filters would have a high correlation while for a dalmatian, the first and third filters would have a high correlation}.
Thus, neurons are connected that alone represent a certain filter but together represent a certain more complex pattern.













% Neural Style Transfer & Gram Matritzen
%https://arxiv.org/abs/1505.07376
%https://ieeexplore.ieee.org/document/1057698

% Summarize work from Claude -> only if relevant...










