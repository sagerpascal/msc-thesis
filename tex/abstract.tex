Deep learning systems have achieved impressive results in recent years and can, among other things, translate texts, conduct conversations, or generate high-quality images. However, these systems are typically trained with backpropagation of error in an end-to-end fashion across all network layers. While this process is very efficient for specific tasks such as classification, it is not neuroscientifically plausible. Moreover, it has various weaknesses, such as a lack of robustness, missing interpretability, and inability to do causal reasoning.

In this thesis, neuroscientific findings that are elementary for the intelligence of living beings such as humans are identified and transferred into a deep learning setting. The focus is on the visual cortex as a biological source of inspiration, while deep learning architectures for image analysis are the target system. Neuroscientific findings refer to biological neurons that mutually excite or inhibit each other through time-dependent electric spikes. On the other hand, deep learning systems have no time dynamics but activations based on mathematical functions. Consequently, a significant contribution of this thesis is to adapt and transfer the neuroscientific findings into the context of deep learning. Specifically, suggestions are made on how self-organisation, net fragments and lateral connections could be used to improve current deep learning systems.

The identified findings are implemented in the form of two concrete models in a deep learning setting. The aim is to demonstrate new architectural ideas rather than outperforming some metrics, such as the accuracy of well-known benchmark datasets. Furthermore, the proposed architectures are kept close to the well-established deep learning framework and are not intended to be biologically plausible systems. Specifically, a model with vertical self-organisation and a model with horizontal self-organisation is proposed. The model with vertical self-organisation optimises each model layer separately using proxy objective functions. Therefore, new concepts are introduced that allow all layers to be trained simultaneously while the model can still learn hierarchical features across layers. The second model with horizontal self-organisation splits the input data into smaller patches and distributes them to independently trained variational autoencoders. Each model sees only a patch of the input data and relies on local interaction with its neighbouring models to derive an appropriate image representation.

TODO: Conclusion / findings once experiments are completed.