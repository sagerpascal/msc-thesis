Deep learning systems have achieved impressive results in recent years and can, among other things, translate texts, conduct conversations as chatbots, or generate images with high quality. These systems are typically trained with backpropagation of error in an end-to-end fashion across all network layers. While this process is very efficient for specific tasks such as classification, it is not neuroscientifically plausible and has various weaknesses such as lack of robustness, missing interpretability, and inability to to causal reasoning.

In this thesis, neuroscientific findings that are elementary for the intelligence of living beings such as humans are identified and transferred into a deep learning setting. Thereby, the focus is on the visual cortex as a biological source of inspiration and deep learning architectures for image processing as target system. Neuroscientific findings refer to biological neurons that mutually excite or inhibit each other through time-dependent electric spikes. Deep learning systems, on the other hand, have no time dynamics and have activations based on floating point numbers instead of electric pulses. Consequently, a major contribution of this thesis is to transfer the neuroscientific findings into the context of deep learning.

The identified findings are implemented in the form of two concrete models in a deep learning setting. Thereby, the aim is to demonstrate new architectural ideas and not to outperform some metrics of well-known benchmark datasets. In addition, the proposed architectures are kept close to the well-established deep learning framework and are not intended to be biologically plausible systems. Specifically, a model with vertical self-organisation and a model with horizontal self-organisation are proposed. The model with vertical self-organisation optimises each model layer separately. New concepts are introduced that allow all layers to be trained simultaneously while the model is still able to learn hierarchical features across layers. The second model with horizontal self-organisation splits the input data into smaller units and distributes them to independently trained models. Here, each model sees only a patch of the input data and relies on local interaction with its neighbouring models to derive an appropriate image representation.

TODO: Conclusion / findings once experiments are completed.