%% intro.tex
Mankind has always tried to simplify its life through technological progress.
Thousands of years before Christ the wheel was invented, later the pulley, the printing press, and the steam locomotive.
At the beginning of the 19th century, the first generators were built to produce electricity, and in 1835, the first light bulb was invented by James Bowman Lindsay\sidenote{and not, as so often falsely claimed, by Thomas Alva Edision}.
In the course of time more and more complex electrical circuits were produced and finally in 1941 the first digital calculating machine, the computer was developed.
This calculating machine is able to perform various arithmetic operations on the basis of commands.
Through the development of transistors, more and more complex computers could be produced, which are able to execute various tasks.
The definition of these tasks are captured in software.
The computer has been so successful in fact that it has spawned its own scientific discipline, Computer Science.
Nowadays it is impossible to imagine life without computers: almost every household and company owns computers.
Computers facilitate various tasks, from communication to the acquisition of knowledge.
For all these tasks, software developers have created appropriate tools.
Software development is the process of writing a script with a programming language to specify how the computer should behave for a given input.
Simply put: A software program tells the computer what to do if the user enters a command.
This works very well if the tasks is clearly defined and can be described precisely.
However, there exists tasks which are almost impossible to program.
For example, writing a script that detects cats in images is almost impossible because we cannot describe how a cat looks like\sidenote{at least not on a pixel-level basis so that we can simply compare a given image with our description}.

Therefore, computer scientists came up with the idea to not just program such tasks but to let the computer learn them instead.
Machine learning (ML) are algorithms that are able to learn and adapt without following explicit instructions such as program code.
Instead, they use statistical models to analyse data, to find patterns in the data and to draw inferences out of it.
Machine learning has become an indispensable part of our everyday lives.
For example, we use it for machine translation, transport and logistics organization, product recommendations, fraud detection, self-driving cars, unlocking smartphones, improving video games, speech recognition, and much more.
A sub-branch of Machine Learning, namely Deep Learning, has made waves in the last decade.
Breakthroughs are being made with this technology are made almost monthly and allows us to execute more and more tasks.

However, such DL system are usually good at one ore a few closely related tasks.
In fact, they have they have some crucial flaws by definition (c.f. Section \secref{limitationsDL}) which cannot be resolved for sure in the current DL framework.
One of the Godfathers of Deep Learning is the Turing Award winner Geoffrey Hinton. 
Especially his contribution to back propagation (c.f. Section \secref{ann}) has shaped the field.
Back propagation is \emph{the} core learning algorithm of DL systems and was developed in 1986.
More than 30 years later, in 2017, Hinton says that he is ``deeply suspicious'' about back propagation and in his view we have to ``throw it all away and start again'' to improve current systems fundamentally \sidecite{axios_hinton}.
Considering what DL systems have achieved, this seems a bit extreme.
However, it also shows that the current learning algorithm of such systems has serious flaws.

Mankind is often inspired by nature when it comes to developing novel systems.
The development of artificial intelligence (AI) and Deep Learning has been strongly influenced by, according to our perception, one of (if not the) most intelligent systems on planet Earth, the human brain.
The brain is studied by the scientific field of neuroscience\sidenote{there exist many additional (sub-)fields studying the brain such as cognitive science, cognitive psychology, neurology, and neuropsychology}.
From neuroscience or related fields come various insights on how the human nervous system and especially the brain works.
Much of this knowledge has been gained through observations and experiments on humans or other living creatures.
Often these findings are only what can be measured from the outside, the real core, the mechanism that causes intelligence, remains unknown.

While Deep Learning is clearly inspired by the insights of Neuroscience, the two fields have little in common in their present form.
The implementation of neuroscientific findings has emerged as a subfield in its own right, called Neurocomputing (c.f. Section \secref{neurocomputing}).
In general, neurocomputing is closer related to the functionality of the human brain than Deep Learning.
Neurocomputing has produced many promising algorithms that can overcome some weaknesses faced by deep learning systems. 
Although neurocomputing has also achieved significant breakthroughs, most systems used in everyday life are still based on the principle of Deep Learning.

TODO: deep learning or Deep Learning -> make uniform

\subsection{Motivation}\seclbl{motivation}
Despite the fact that Deep Learning has achieved incredible performance on a variety of tasks it is still questionable whether the current methodology is enough to achieve real (or at least more advanced) intelligence (c.f. Section \secref*{limitationsDL}).
Many of the current limitations are tackled by approaches from the field of neurocomputing (c.f. Section \secref*{neurocomputing}).
However, even tough algorithms from the field of neurocomputing  have interesting properties, it usually does not perform as good as Deep Learning and often works on specific or small data only.

Neuroscience provides a source of inspiration for AI algorithms, independent of mathematical models.
So far, neuroscientists have studied the building blocks of the brain, their responsibilities in the overall process as well as how they interconnect and communicate.
The ``algorithm'' that makes the brain intelligent remains unknown.
Furthermore, it is not known which observed functionality in the brain is really part of this algorithm and which are just consequences of it.
For example, it is hard to tell if the dynamics in the human brain are necessary to achieve intelligence or if this is just nature's way of implementing it.

Renowned scientists \sidecite{von_der_Malsburg_Stadelmann_Grewe_2022} put forward the hypothesis that the core of natural intelligence lies within the self-organization of the brain.
Self-organization is the process by which individual units organize their global behavior by local interactions amongst themselves.
There is no central control unit that orchestrates the units.
In the context of the brain, self-organization primarily affects how neurons are interconnected.
The brains of living beings already have certain structures from birth, which are specified by the DNA.
In the course of time, these structures change.
For example, neurons or connections between neurons may be added or removed.
Thus, the brain adapts to its environment over time.

Such a mechanism has not been successfully implemented in deep learning nor neurocomputing systems.
In deep learning system, the architecture is usually predefined and only the parameters (i.e. weight and biases, c.f. \secref*{ann}) are updated.
In neurocomputing, on the other hand, the theory behind self-organization is often associated with Hebbian Learning (c.f. Section \secref{hebbian}).
this dynamic learning of connections is often associated with Hebbian Learning (c.f. Section \secref{hebbian}).
The theory behind this learning rule can be summarized as ``cells that fire together wire together''\sidecite{science.1372754}.
However, Hebbian learning is usually rather used to update the weight between connections instead of to add or to remove connections.
Connections are therefore not removed or added but can be ``turned off'' and ``turned on'' if the activation function of a neuron uses a threshold below which signals are no longer transmitted\sidenote{if the weights get small enough, the threshold limit cannot be reached and the neurons output is 0}.
In this case, the architecture of the network is to a large part still predefined and self-organization can for example not be used to add additional layers.

This thesis aims to combine the strengths of deep learning and neurocomputing with recent findings of neuroscience.
Especially the hypothesis that self-organization is key for natural intelligence is incorporated in the learning process of modern artificial neural networks.
While in classical Deep Learning the architecture is predefined, in this thesis we attempt to learn not only the parameters but also the architecture itself.
The architecture is built by self-organization. 
his means that local communication between the building blocks defined by an initial architecture takes place and that new connections can be created or existing connections can be removed.
The challenge is how this re-wiring of the connections can be be learned.
It seems certain that the existing learning algorithm back-propagation must either be extended or replaced.
However, proposing a concrete algorithm based on the rather abstract findings from Neuroscience is part of this thesis.


%Recently, von der Malsburg et al. \sidecite{von_der_Malsburg_Stadelmann_Grewe_2022} have published their hypothesis about the key building blocks for a system with general intelligence.
%They point out that building self-organizing sub-networks during training may be one of the keys to fundamentally improve current systems.
%Lehmann \sidecite{lehmann} worked on incorporating a few of these ideas and principles into a DL framework.
%He proposes a laterally connected layer (LCL), a layer that forms lateral intra-layer connections based on Hebbian learning.
%These connections are formed during training based on the input.
%He shows that the LCL layer increases robustness on the popular MNIST dataset.
%However, he also points out potential for improvement of the LCL layers.

%Von der Malsburg et al. \cite{von_der_Malsburg_Stadelmann_Grewe_2022} propose several concepts how current problems in ANNs can be tackled.
%They present systematically sound theoretical foundations, but neither the formulation of a mathematical model nor the translation of their ideas into a concrete application were in the scope of their work.
%Specifically, we do the following...

%TODO...



\subsection{Organization of Thesis}\seclbl{org_thesis}
The remainder of the thesis is organized as follows: In chapter \chref*{fundamentals} we present the fundamentals necessary to understand this thesis. We provide an overview about how deep learning works and what the most common research areas in neurocomputing are. Chapter \chref*{rel_work} presents the work related to this thesis.

TODO....



