
@misc{von_der_malsburg_theory_2022,
	title = {A {Theory} of {Natural} {Intelligence}},
	url = {http://arxiv.org/abs/2205.00002},
	doi = {10.48550/arXiv.2205.00002},
	abstract = {Introduction: In contrast to current AI technology, natural intelligence -- the kind of autonomous intelligence that is realized in the brains of animals and humans to attain in their natural environment goals defined by a repertoire of innate behavioral schemata -- is far superior in terms of learning speed, generalization capabilities, autonomy and creativity. How are these strengths, by what means are ideas and imagination produced in natural neural networks? Methods: Reviewing the literature, we put forward the argument that both our natural environment and the brain are of low complexity, that is, require for their generation very little information and are consequently both highly structured. We further argue that the structures of brain and natural environment are closely related. Results: We propose that the structural regularity of the brain takes the form of net fragments (self-organized network patterns) and that these serve as the powerful inductive bias that enables the brain to learn quickly, generalize from few examples and bridge the gap between abstractly defined general goals and concrete situations. Conclusions: Our results have important bearings on open problems in artificial neural network research.},
	urldate = {2022-07-11},
	publisher = {arXiv},
	author = {von der Malsburg, Christoph and Stadelmann, Thilo and Grewe, Benjamin F.},
	month = apr,
	year = {2022},
	note = {arXiv:2205.00002 [cs, q-bio]},
	keywords = {Computer Science - Artificial Intelligence, I.2, Quantitative Biology - Neurons and Cognition},
}

@article{yarats_improving_2021,
	title = {Improving {Sample} {Efficiency} in {Model}-{Free} {Reinforcement} {Learning} from {Images}},
	volume = {35},
	issn = {2374-3468, 2159-5399},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/17276},
	doi = {10.1609/aaai.v35i12.17276},
	abstract = {Training an agent to solve control tasks directly from high-dimensional images with model-free reinforcement learning (RL) has proven difficult. A promising approach is to learn a latent representation together with the control policy. However, fitting a high-capacity encoder using a scarce reward signal is sample inefficient and leads to poor performance.
Prior work has shown that auxiliary losses, such as image reconstruction, can aid efficient representation learning.  
However, incorporating reconstruction loss into an off-policy learning algorithm often leads to training instability. We explore the underlying reasons and 
identify variational autoencoders, used by previous investigations, as the cause of the divergence.   
Following these findings, we propose effective techniques to improve training stability. 
This results in a simple approach capable of
matching state-of-the-art model-free and model-based algorithms on MuJoCo control tasks. Furthermore, our approach demonstrates robustness to observational noise, surpassing existing approaches in this setting. Code, results, and videos are anonymously available at https://sites.google.com/view/sac-ae/home.},
	number = {12},
	urldate = {2023-06-24},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Yarats, Denis and Zhang, Amy and Kostrikov, Ilya and Amos, Brandon and Pineau, Joelle and Fergus, Rob},
	month = may,
	year = {2021},
	pages = {10674--10681},
}

@article{sager_unsupervised_2022,
	title = {Unsupervised {Domain} {Adaptation} for {Vertebrae} {Detection} and {Identification} in {3D} {CT} {Volumes} {Using} a {Domain} {Sanity} {Loss}},
	volume = {8},
	copyright = {All rights reserved},
	issn = {2313-433X},
	url = {https://www.mdpi.com/2313-433X/8/8/222},
	doi = {10.3390/jimaging8080222},
	abstract = {A variety of medical computer vision applications analyze 2D slices of computed tomography (CT) scans, whereas axial slices from the body trunk region are usually identified based on their relative position to the spine. A limitation of such systems is that either the correct slices must be extracted manually or labels of the vertebrae are required for each CT scan to develop an automated extraction system. In this paper, we propose an unsupervised domain adaptation (UDA) approach for vertebrae detection and identification based on a novel Domain Sanity Loss (DSL) function. With UDA the model’s knowledge learned on a publicly available (source) data set can be transferred to the target domain without using target labels, where the target domain is defined by the specific setup (CT modality, study protocols, applied pre- and processing) at the point of use (e.g., a specific clinic with its specific CT study protocols). With our approach, a model is trained on the source and target data set in parallel. The model optimizes a supervised loss for labeled samples from the source domain and the DSL loss function based on domain-specific “sanity checks” for samples from the unlabeled target domain. Without using labels from the target domain, we are able to identify vertebra centroids with an accuracy of 72.8\%. By adding only ten target labels during training the accuracy increases to 89.2\%, which is on par with the current state-of-the-art for full supervised learning, while using about 20 times less labels. Thus, our model can be used to extract 2D slices from 3D CT scans on arbitrary data sets fully automatically without requiring an extensive labeling effort, contributing to the clinical adoption of medical imaging by hospitals.},
	language = {en},
	number = {8},
	urldate = {2022-09-01},
	journal = {Journal of Imaging},
	author = {Sager, Pascal and Salzmann, Sebastian and Burn, Felice and Stadelmann, Thilo},
	month = aug,
	year = {2022},
	pages = {222},
}

@article{long_survey_2022,
	title = {A survey on adversarial attacks in computer vision: {Taxonomy}, visualization and future directions},
	volume = {121},
	issn = {01674048},
	shorttitle = {A survey on adversarial attacks in computer vision},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167404822002413},
	doi = {10.1016/j.cose.2022.102847},
	language = {en},
	urldate = {2023-06-24},
	journal = {Computers \& Security},
	author = {Long, Teng and Gao, Qi and Xu, Lili and Zhou, Zhangbing},
	month = oct,
	year = {2022},
	pages = {102847},
}

@article{radford_improving_2018,
	title = {Improving language understanding by generative pre-training},
	url = {https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf},
	author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	year = {2018},
}

@misc{rosenbloom_defining_2023,
	title = {Defining and {Explorting} the {Intelligence} {Space}},
	url = {http://arxiv.org/abs/2306.06499},
	doi = {10.48550/arXiv.2306.06499},
	abstract = {Intelligence is a difficult concept to define, despite many attempts at doing so. Rather than trying to settle on a single definition, this article introduces a broad perspective on what intelligence is, by laying out a cascade of definitions that induces both a nested hierarchy of three levels of intelligence and a wider-ranging space that is built around them and approximations to them. Within this intelligence space, regions are identified that correspond to both natural -- most particularly, human -- intelligence and artificial intelligence (AI), along with the crossover notion of humanlike intelligence. These definitions are then exploited in early explorations of four more advanced, and likely more controversial, topics: the singularity, generative AI, ethics, and intellectual property.},
	urldate = {2023-06-24},
	publisher = {arXiv},
	author = {Rosenbloom, Paul S.},
	month = jun,
	year = {2023},
	note = {arXiv:2306.06499 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{mitchell_debate_2023,
	title = {The debate over understanding in {AI}’s large language models},
	volume = {120},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/10.1073/pnas.2215907120},
	doi = {10.1073/pnas.2215907120},
	abstract = {We survey a current, heated debate in the artificial intelligence (AI) research community on whether large pretrained language models can be said to understand language—and the physical and social situations language encodes—in any humanlike sense. We describe arguments that have been made for and against such understanding and key questions for the broader sciences of intelligence that have arisen in light of these arguments. We contend that an extended science of intelligence can be developed that will provide insight into distinct modes of understanding, their strengths and limitations, and the challenge of integrating diverse forms of cognition.},
	language = {en},
	number = {13},
	urldate = {2023-06-24},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Mitchell, Melanie and Krakauer, David C.},
	month = mar,
	year = {2023},
	pages = {e2215907120},
}

@article{bertolini_machine_2021,
	title = {Machine {Learning} for industrial applications: {A} comprehensive literature review},
	volume = {175},
	issn = {09574174},
	shorttitle = {Machine {Learning} for industrial applications},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S095741742100261X},
	doi = {10.1016/j.eswa.2021.114820},
	language = {en},
	urldate = {2023-06-24},
	journal = {Expert Systems with Applications},
	author = {Bertolini, Massimo and Mezzogori, Davide and Neroni, Mattia and Zammori, Francesco},
	month = aug,
	year = {2021},
	pages = {114820},
}

@article{ning_review_2019,
	title = {A {Review} of {Deep} {Learning} {Based} {Speech} {Synthesis}},
	volume = {9},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/9/19/4050},
	doi = {10.3390/app9194050},
	abstract = {Speech synthesis, also known as text-to-speech (TTS), has attracted increasingly more attention. Recent advances on speech synthesis are overwhelmingly contributed by deep learning or even end-to-end techniques which have been utilized to enhance a wide range of application scenarios such as intelligent speech interaction, chatbot or conversational artificial intelligence (AI). For speech synthesis, deep learning based techniques can leverage a large scale of {\textless}text, speech{\textgreater} pairs to learn effective feature representations to bridge the gap between text and speech, thus better characterizing the properties of events. To better understand the research dynamics in the speech synthesis field, this paper firstly introduces the traditional speech synthesis methods and highlights the importance of the acoustic modeling from the composition of the statistical parametric speech synthesis (SPSS) system. It then gives an overview of the advances on deep learning based speech synthesis, including the end-to-end approaches which have achieved start-of-the-art performance in recent years. Finally, it discusses the problems of the deep learning methods for speech synthesis, and also points out some appealing research directions that can bring the speech synthesis research into a new frontier.},
	language = {en},
	number = {19},
	urldate = {2023-06-24},
	journal = {Applied Sciences},
	author = {Ning, Yishuang and He, Sheng and Wu, Zhiyong and Xing, Chunxiao and Zhang, Liang-Jie},
	month = sep,
	year = {2019},
	pages = {4050},
}

@article{otter_survey_2021,
	title = {A {Survey} of the {Usages} of {Deep} {Learning} for {Natural} {Language} {Processing}},
	volume = {32},
	issn = {2162-237X, 2162-2388},
	url = {https://ieeexplore.ieee.org/document/9075398/},
	doi = {10.1109/TNNLS.2020.2979670},
	number = {2},
	urldate = {2023-06-24},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Otter, Daniel W. and Medina, Julian R. and Kalita, Jugal K.},
	month = feb,
	year = {2021},
	pages = {604--624},
}

@article{bhatt_cnn_2021,
	title = {{CNN} {Variants} for {Computer} {Vision}: {History}, {Architecture}, {Application}, {Challenges} and {Future} {Scope}},
	volume = {10},
	issn = {2079-9292},
	shorttitle = {{CNN} {Variants} for {Computer} {Vision}},
	url = {https://www.mdpi.com/2079-9292/10/20/2470},
	doi = {10.3390/electronics10202470},
	abstract = {Computer vision is becoming an increasingly trendy word in the area of image processing. With the emergence of computer vision applications, there is a significant demand to recognize objects automatically. Deep CNN (convolution neural network) has benefited the computer vision community by producing excellent results in video processing, object recognition, picture classification and segmentation, natural language processing, speech recognition, and many other fields. Furthermore, the introduction of large amounts of data and readily available hardware has opened new avenues for CNN study. Several inspirational concepts for the progress of CNN have been investigated, including alternative activation functions, regularization, parameter optimization, and architectural advances. Furthermore, achieving innovations in architecture results in a tremendous enhancement in the capacity of the deep CNN. Significant emphasis has been given to leveraging channel and spatial information, with a depth of architecture and information processing via multi-path. This survey paper focuses mainly on the primary taxonomy and newly released deep CNN architectures, and it divides numerous recent developments in CNN architectures into eight groups. Spatial exploitation, multi-path, depth, breadth, dimension, channel boosting, feature-map exploitation, and attention-based CNN are the eight categories. The main contribution of this manuscript is in comparing various architectural evolutions in CNN by its architectural change, strengths, and weaknesses. Besides, it also includes an explanation of the CNN’s components, the strengths and weaknesses of various CNN variants, research gap or open challenges, CNN applications, and the future research direction.},
	language = {en},
	number = {20},
	urldate = {2023-06-24},
	journal = {Electronics},
	author = {Bhatt, Dulari and Patel, Chirag and Talsania, Hardik and Patel, Jigar and Vaghela, Rasmika and Pandya, Sharnil and Modi, Kirit and Ghayvat, Hemant},
	month = oct,
	year = {2021},
	pages = {2470},
}

@article{dabre_survey_2021,
	title = {A {Survey} of {Multilingual} {Neural} {Machine} {Translation}},
	volume = {53},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3406095},
	doi = {10.1145/3406095},
	abstract = {We present a survey on multilingual neural machine translation (MNMT), which has gained a lot of traction in recent years. MNMT has been useful in improving translation quality as a result of translation knowledge transfer (transfer learning). MNMT is more promising and interesting than its statistical machine translation counterpart, because end-to-end modeling and distributed representations open new avenues for research on machine translation. Many approaches have been proposed to exploit multilingual parallel corpora for improving translation quality. However, the lack of a comprehensive survey makes it difficult to determine which approaches are promising and, hence, deserve further exploration. In this article, we present an in-depth survey of existing literature on MNMT. We first categorize various approaches based on their central use-case and then further categorize them based on resource scenarios, underlying modeling principles, core-issues, and challenges. Wherever possible, we address the strengths and weaknesses of several techniques by comparing them with each other. We also discuss the future directions for MNMT. This article is aimed towards both beginners and experts in NMT. We hope this article will serve as a starting point as well as a source of new ideas for researchers and engineers interested in MNMT.},
	language = {en},
	number = {5},
	urldate = {2023-06-24},
	journal = {ACM Computing Surveys},
	author = {Dabre, Raj and Chu, Chenhui and Kunchukuttan, Anoop},
	month = sep,
	year = {2021},
	pages = {1--38},
}

@book{ivakhnenko_cybernetic_1965,
	address = {New York},
	title = {Cybernetic {Predicting} {Devices}},
	publisher = {CCM Information Corporation},
	author = {Ivakhnenko, Aleksei Grigorévich and Lapa, Valentin Grigorévich},
	year = {1965},
}

@misc{liu_summary_2023,
	title = {Summary of {ChatGPT}/{GPT}-4 {Research} and {Perspective} {Towards} the {Future} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2304.01852},
	doi = {10.48550/arXiv.2304.01852},
	abstract = {This paper presents a comprehensive survey of ChatGPT and GPT-4, state-of-the-art large language models (LLM) from the GPT series, and their prospective applications across diverse domains. Indeed, key innovations such as large-scale pre-training that captures knowledge across the entire world wide web, instruction fine-tuning and Reinforcement Learning from Human Feedback (RLHF) have played significant roles in enhancing LLMs' adaptability and performance. We performed an in-depth analysis of 194 relevant papers on arXiv, encompassing trend analysis, word cloud representation, and distribution analysis across various application domains. The findings reveal a significant and increasing interest in ChatGPT/GPT-4 research, predominantly centered on direct natural language processing applications, while also demonstrating considerable potential in areas ranging from education and history to mathematics, medicine, and physics. This study endeavors to furnish insights into ChatGPT's capabilities, potential implications, ethical concerns, and offer direction for future advancements in this field.},
	urldate = {2023-06-24},
	publisher = {arXiv},
	author = {Liu, Yiheng and Han, Tianle and Ma, Siyuan and Zhang, Jiayue and Yang, Yuanyuan and Tian, Jiaming and He, Hao and Li, Antong and He, Mengshen and Liu, Zhengliang and Wu, Zihao and Zhu, Dajiang and Li, Xiang and Qiang, Ning and Shen, Dingang and Liu, Tianming and Ge, Bao},
	month = may,
	year = {2023},
	note = {arXiv:2304.01852 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{openai_gpt-4_2023,
	title = {{GPT}-4 {Technical} {Report}},
	url = {http://arxiv.org/abs/2303.08774},
	doi = {10.48550/arXiv.2303.08774},
	abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
	urldate = {2023-06-24},
	publisher = {arXiv},
	author = {OpenAI},
	month = mar,
	year = {2023},
	note = {arXiv:2303.08774 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{bubeck_sparks_2023,
	title = {Sparks of {Artificial} {General} {Intelligence}: {Early} experiments with {GPT}-4},
	shorttitle = {Sparks of {Artificial} {General} {Intelligence}},
	url = {http://arxiv.org/abs/2303.12712},
	doi = {10.48550/arXiv.2303.12712},
	abstract = {Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4, was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4's performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4's capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reflections on societal influences of the recent technological leap and future research directions.},
	urldate = {2023-06-24},
	publisher = {arXiv},
	author = {Bubeck, Sébastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and Nori, Harsha and Palangi, Hamid and Ribeiro, Marco Tulio and Zhang, Yi},
	month = apr,
	year = {2023},
	note = {arXiv:2303.12712 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}
